# TelecomX_parte2_BR
# Autor: Saulo Pereira da Silva


üìä An√°lise de Evas√£o de Clientes (Churn) em Telecomunica√ß√µes
Este projeto foca na an√°lise e modelagem preditiva da evas√£o de clientes (churn) no setor de telecomunica√ß√µes. Utilizaremos dados de clientes para identificar os principais fatores que levam √† desist√™ncia do servi√ßo e construir modelos de Machine Learning capazes de prever quais clientes t√™m maior probabilidade de evadir.

üéØ Objetivo do Projeto
O objetivo principal √© identificar padr√µes e caracter√≠sticas de clientes que evadem, bem como desenvolver modelos preditivos que permitam √† empresa tomar a√ß√µes proativas para reten√ß√£o.

üöÄ Etapas do Projeto
O projeto √© dividido nas seguintes etapas principais:

1. üìÇ Extra√ß√£o e Carregamento de Dados
Carregar o dataset de clientes de telecomunica√ß√µes (formato CSV) que foi previamente tratado e limpo.

Garantir que o arquivo cont√©m apenas as colunas relevantes, com dados corrigidos e padronizados da parte 1 do desafio Telecom X.

2. üßπ Pr√©-processamento de Dados
Remo√ß√£o de Colunas Irrelevantes: Eliminar colunas que n√£o agregam valor √† an√°lise ou aos modelos preditivos, como identificadores √∫nicos de cliente (customerID).

Encoding de Vari√°veis Categ√≥ricas: Transformar vari√°veis textuais (categ√≥ricas) em formato num√©rico, utilizando OneHotEncoder, para torn√°-las compat√≠veis com algoritmos de Machine Learning.

Verifica√ß√£o e Balanceamento de Classes: Analisar a propor√ß√£o da vari√°vel alvo (Churn) para identificar desequil√≠brios. Se necess√°rio, aplicar t√©cnicas de balanceamento de classes como SMOTE para criar um dataset mais equilibrado, o que √© crucial para o desempenho do modelo em classes minorit√°rias.

3. üìà An√°lise Explorat√≥ria e Sele√ß√£o de Vari√°veis
An√°lise de Correla√ß√£o: Visualizar a matriz de correla√ß√£o entre as vari√°veis num√©ricas para identificar relacionamentos, especialmente com a vari√°vel Churn.

An√°lises Direcionadas: Investigar a rela√ß√£o de vari√°veis-chave como tenure (tempo de contrato) e TotalCharges (total gasto) com a evas√£o, utilizando gr√°ficos como boxplots.

Normaliza√ß√£o/Padroniza√ß√£o: Preparar os dados num√©ricos utilizando StandardScaler para modelos que s√£o sens√≠veis √† escala (ex: Regress√£o Log√≠stica, KNN). Modelos baseados em √°rvore (ex: √Årvore de Decis√£o, Random Forest) n√£o exigem essa etapa.

4. ü§ñ Modelagem Preditiva
Separa√ß√£o de Dados: Dividir o dataset em conjuntos de treino e teste (com uma propor√ß√£o comum de 70/30 ou 80/20) para avaliar o desempenho dos modelos de forma justa. A estratifica√ß√£o pela vari√°vel alvo √© aplicada para manter a propor√ß√£o de Churn em ambos os conjuntos.

Cria√ß√£o e Treinamento de Modelos: Construir e treinar pelo menos dois modelos de Machine Learning distintos:

Regress√£o Log√≠stica: Um modelo linear que exige dados padronizados.

√Årvore de Decis√£o: Um modelo baseado em √°rvore que n√£o necessita de padroniza√ß√£o.

Avalia√ß√£o do Modelo: Avaliar o desempenho de cada modelo utilizando m√©tricas como Relat√≥rio de Classifica√ß√£o (Precision, Recall, F1-Score) e Matriz de Confus√£o.

5. üìã Interpreta√ß√£o e Conclus√µes
An√°lise de Import√¢ncia das Vari√°veis: Investigar quais vari√°veis s√£o mais relevantes para a previs√£o de evas√£o em cada modelo:

Regress√£o Log√≠stica: Analisar os coeficientes para entender a contribui√ß√£o de cada vari√°vel.

√Årvore de Decis√£o: Utilizar a funcionalidade feature_importances_ para identificar as vari√°veis mais impactantes.

Relat√≥rio Final: Elaborar um relat√≥rio detalhado destacando os principais fatores que influenciam a evas√£o, comparando o desempenho dos modelos e propondo estrat√©gias de reten√ß√£o de clientes baseadas nos insights obtidos.

üõ†Ô∏è Ferramentas e Bibliotecas Utilizadas
Python

Pandas: Manipula√ß√£o e an√°lise de dados.

NumPy: Suporte a opera√ß√µes num√©ricas.

Matplotlib e Seaborn: Visualiza√ß√£o de dados.

Scikit-learn (sklearn): Pr√©-processamento de dados, modelos de Machine Learning e avalia√ß√£o de modelos.

Imbalanced-learn (imblearn): Para t√©cnicas de balanceamento de classes (ex: SMOTE).

‚öôÔ∏è Como Executar o Projeto
Clone o Reposit√≥rio: (Assumindo que o c√≥digo estar√° em um reposit√≥rio)

Bash

git clone <URL_DO_REPOSITORIO>
cd <NOME_DO_REPOSITORIO>
Prepara√ß√£o do Ambiente:

Certifique-se de ter o Google Colab configurado ou um ambiente Python com as bibliotecas listadas instaladas.

Instale as bibliotecas necess√°rias:

Bash

pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn
Carregue o Dataset:

Fa√ßa o upload do seu arquivo CSV tratado (ex: TelecomX_Tratado.csv) para o ambiente do Google Colab (via menu "Arquivos" > "Fazer upload") ou monte seu Google Drive e forne√ßa o caminho correto no script.

Execute o Notebook/Script:

Abra o arquivo .ipynb (se for um notebook Jupyter/Colab) ou execute o script Python (.py) c√©lula por c√©lula ou o arquivo completo.

ü§ù Contribui√ß√µes
Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues ou pull requests.

